<!DOCTYPE html>
<html>
<head>
   <title>JMockit - Tutorial - Measuring code coverage</title>
   <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
   <link rel="stylesheet" type="text/css" href="../prettify.css"/>
   <link rel="shortcut icon" type="image/x-icon" href="../favicon.ico"/>
   <script type="text/javascript" src="../highlight.pack.js"></script>
   <script type="text/javascript">hljs.initHighlightingOnLoad()</script>
</head>
<body>
<h1 class="header">
   <a href="../index.html">JMockit</a>
   <span>An automated testing toolkit for Java</span>
   <span class="navigation">
      <a href="Faking.html"><img src="go-previous.png" title="Previous chapter"></a>
      <a href="../tutorial.html"><img src="go-home.png" title="Contents"></a>
   </span>
</h1>
<h1 id="top">
   <a href="#">Measuring code coverage</a>
</h1>
<table align="center" width="100%"><tr>
   <td>
      <ol class="contents">
         <li><a href="#metric">The coverage metric</a></li>
         <li>
            <a href="#output">Types of coverage output</a>
            <ol><li><a href="#callPoints">Call points</a></li></ol>
         </li>
         <li><a href="#configuration">Configuring the coverage tool</a></li>
         <li>
            <a href="#merging">Aggregated reports for multiple test runs</a>
            <ol>
               <li><a href="#serial">Generating an aggregate report from multiple data files</a></li>
               <li><a href="#serial-append">Generating an aggregate report from a single data file appended after each test run</a></li>
            </ol>
         </li>
      </ol>
   </td>
   <td>
      <ol class="contents">
         <li value="5"><a href="#checking">Checking minimum coverage</a></li>
         <li>
            <a href="#maven">Activating coverage in a Maven project</a>
            <ol><li><a href="#site">Including the HTML report in a Maven site</a></li></ol>
         </li>
         <li>
            <a href="#switching">Turning coverage off</a>
            <br><br><br><br>
         </li>
      </ol>
   </td>
</tr></table>
<p>
   <a target="_blank" href="http://en.wikipedia.org/wiki/Code_coverage"><em>Code coverage</em></a> consists of a set of software metrics
   that can tell you how much of the production code is covered by a given test suite.
   It's purely quantitative, and does not say anything about the <em>quality</em> of either the production code or the test code.
   That said, the examination of code coverage reports will sometimes lead to the discovery of unreachable code which can be eliminated.
   But more importantly, such reports can be used as a guide for the discovery of missing tests.
   This is not only useful when creating tests for existing production code, but also when writing tests first, such as in the practice of
   TDD (Test Driven Development).
</p>

<h2 id="metric">
   <a href="#line">1 The coverage metric</a>
</h2>
<p>
   The <em>coverage metric</em> produced by the tool tells us how much of the <em>executable code</em> in a source file has been exercised
   by tests, and also how many of the instance and static non-final <em>fields</em> were fully exercised by the test run.
</p>
<p>
   Each executable line of code can be <em>uncovered</em>, <em>covered</em>, or <em>partially covered</em>.
   The third case can happen, for example, with lines of code containing multiple logical conditions in a complex boolean expression.
   The tool identifies all three cases, computing the <em>coverage percentage</em> for each executable line of code accordingly:
   <strong>0%</strong> for an uncovered line, <strong>100%</strong> for a covered line, or some value in between for a partially covered
   line.
</p>
<p>
   Regarding fields, to be fully exercised, each must have the last value assigned to it read by at least one test.
</p>
<p>
   The coverage percentage for a source file is calculated as <code>100 * (NE + NFE) / (NS + NF)</code>, where <code>NS</code> is the total
   number of line segments, <code>NF</code> the number of non-final fields, <code>NE</code> the number of executed segments, and
   <code>NFE</code> the number of fully exercised fields.
</p>
<p>
   The percentage for a <em>package</em>, in turn, is calculated from the total and covered numbers of segments and fields in the whole set
   of source files belonging to the package.
   Finally, the <em>total code coverage</em> percentage is computed by the same formula on the totals for all packages.
</p>

<h2 id="output">
   <a href="#output">2 Types of coverage output</a>
</h2>
<p>
   The JMockit Coverage tool can generate the following types of output:
</p>
<ol>
   <li>
      <strong>HTML reports</strong>: a multi-page HTML report is written in the "coverage-report" directory, under the current working
      directory (a different output directory can be specified if needed).
      The directory is created if it doesn't yet exist; its contents are overwritten if previously generated.
      The report will include pages containing all Java source files covered by the test suite.
      By default, the tool looks for "<code>.java</code>" source files inside all directories of name "<code>src</code>" found directly or
      indirectly under the current working directory; any intermediate sub-directories between "<code>src</code>" and the top-level package
      directory, such as "<code>src/java</code>" for example, are also searched.
   </li>
   <li>
      <strong>Coverage data files</strong>: a single serialized file of name "<code>coverage.ser</code>" is written under the current
      working directory or a specified output directory.
      If the file already exists, its contents are either overwritten or appended with the in-memory results of the current test run, as
      specified.
      <br>
      These files can be read and processed by external tools.
      The <code>mockit.coverage.data.CoverageData.readDataFromFile(File)</code> method will create a new
      <code class="type">CoverageData</code> instance with all the coverage data available in a given serialized file.
   </li>
</ol>

<h3 id="callPoints">
   <a href="#callPoints">2.1 Call points</a>
</h3>
<p>
   When running a test suite with the coverage tool, there is optional "call point" information which can be gathered, as selected by the
   user.
   A <em>call point</em> is the point in the source test code from which a specific line of production code was exercised.
</p>
<p>
   Generating coverage with this extra information takes more time and produces significantly larger output;
   on the other hand, it can be useful to know which lines of test code caused a given line of production code to be executed during the
   test run.
   When included in the HTML report, the list of call points appears hidden at first but can be easily viewed by clicking on each executable
   line of code.
</p>

<h2 id="configuration">
   <a href="#configuration">3 Configuring the coverage tool</a>
</h2>
<p>
   To activate the Coverage tool in a JUnit/TestNG test run, use the <code>-javaagent</code> JVM initialization parameter, and specify at
   least one of the "<code>coverage-output</code>" and "<code>coverage-classes</code>" <em>system properties</em>.
   (See <a href="Introduction.html#runningTests">Running tests with JMockit</a> for more details.)
   All aspects of the tool's behavior can be configured by setting one or more of the following properties.
</p>
<ol>
   <li>
      <code>coverage-<strong>output</strong></code>: one or more comma-separated values between <strong><code>html</code></strong>,
      <strong><code>html-cp</code></strong> ("cp" = "call points"), <strong><code>html-nocp</code></strong>,
      <strong><code>serial</code></strong>, and <strong><code>serial-append</code></strong>, which select the kind of output to be generated
      at the end of the test run.
      The default is to generate the HTML report with no call points (<code>html</code> = <code>html-nocp</code>).
      <br>
      The "html", "html-cp" and "html-nocp" values are mutually exclusive, just like "serial" and "serial-append".
      However, it <em>is</em> valid to have one of each pair specified at the same time.
      In such a case, at the end of the test run both kinds of output will be written.
      <br>
      The presence of "<code>serial</code>" or "<code>serial-append</code>" causes a <em>serialized data file</em> of name
      "<code>coverage.ser</code>" to be generated; with "<code>serial-append</code>", coverage data gathered by the current test run will be
      <em>appended</em> to the contents of a previously existing data file (if said file doesn't exist, it has the same effect as
      "<code>serial</code>").
   </li>
   <li>
      <code>coverage-<strong>outputDir</strong></code>: absolute or relative path to the output directory, to be used for writing any
      "<code>coverage.ser</code>" or "<code>index.html</code>" files (plus the remaining "<code>.html</code>" files of the HTML report, in
      automatically created sub-directories).
      By default, the current working directory of the running JVM is used, with all HTML pages written into a
      "<code>coverage-report</code>" sub-directory.
   </li>
   <li>
      <code>coverage-<strong>srcDirs</strong></code>: comma-separated list of Java source directories to be searched when generating an HTML
      report.
      (This is not relevant for the serialized data file.)
      Each directory is specified by an absolute or relative path.
      If no such directory is specified, all "<code>src</code>" directories under the current working directory are searched.
      If, however, the property is set to the empty string, then no source files are searched, and only the <code>index.html</code> file is
      generated.
   </li>
   <li>
      <code>coverage-<strong>classes</strong></code>:
      Either an OS-like regular expression (with the typical "<code>*</code>" and "<code>?</code>" wildcards), or a
      <a target="_blank" href="http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html">java.util.regex</a>-conformable
      regular expression.
      The given expression will be used to select the classes (by fully qualified name) from production code which should be considered for
      coverage.
      By default, all classes in production code loaded during the test run and which are not inside jar files are considered.
      <br>
      For example, "<code>some.package.*</code>" selects all classes under <code>some.package</code> or any sub-package.
      <br>
      As a special case, if the property is specified as "<code>loaded</code>", then all classes will be considered, but only those which
      get loaded by the JVM during the test run; classes that are part of the codebase but never get loaded are left out.
      This is very useful when the test run includes only a few tests, targeting only a subset of the codebase.
   </li>
   <li>
      <code>coverage-<strong>excludes</strong></code>:
      The same as the previous property, but for class names which should be excluded from consideration when instrumenting classes for
      coverage.
      This property can be used together with <code>coverage-classes</code> or on its own.
      By default, no classes between those selected for coverage are excluded from consideration.
   </li>
   <li>
      <code>coverage-<strong>check</strong></code>:
      one or more semicolon-separated rules specifying <em>minimum coverage</em> checks to be performed at the end of a test run.
      By default, no such checks are performed.
      For details, see the <a href="#checking">Checking minimum coverage</a> section.
   </li>
</ol>
<p>
   Note that you should be able to easily specify these properties inside a Maven <code>surefire</code> plugin configuration, or a test run
   configuration for your Java IDE of choice, using either JUnit or TestNG; no JMockit-specific plugin is needed.
</p>

<h2 id="merging">
   <a href="#merging">4 Aggregated reports for multiple test runs</a>
</h2>
<p>
   When the coverage tool generates a report at the end of a test run, it always overwrites any previous report.
   Normally, the coverage data from which the report is generated reflects only what was gathered during the current test run.
   Now suppose you have multiple test suites or test run configurations, and you want to generate a single aggregated HTML report for the
   code covered by the full set of tests.
   Here is where the "coverage.ser" serialized data files come in.
</p>
<p>
   To activate the generation of these files, we simply set the <code>coverage-output</code> system property to a value containing
   "<code>serial</code>" or "<code>serial-append</code>".
   As these two values suggest, there are different ways to combine multiple coverage data files.
   The following sub-sections provide the details for each case.
</p>

<h3 id="serial">
   <a href="#serial">4.1 Generating an aggregate report from multiple data files</a>
</h3>
<p>
   Suppose we want to gather coverage data from multiple test runs and later generate an aggregate HTML report merging together the results
   from all test runs.
   Each test run needs to generate its own <code>coverage.ser</code> file, so that later they can be merged together in a final step which
   produces the report; therefore, each test run should be configured with "<code>coverage-output=serial</code>".
   Note that, in order to preserve the original <code>coverage.ser</code> output files generated by each test run, they will need to be
   written or copied into different output directories.
</p>
<p>
   Assuming that two or more <code>coverage.ser</code> files are available in separate directories, an aggregate report can be generated
   from them by executing the <code>mockit.coverage.CodeCoverage.main</code> method (a regular Java "main" method).
   To facilitate this, the <code>jmockit-1.x.jar</code> file is <em>executable</em>.
   As an example, the following Ant task could be used:
</p>
<pre><code>&lt;java fork="yes" dir="myBaseDir" jar="jmockit-1.x.jar">
   &lt;jvmarg line="-Dcoverage-output=html"/>
   &lt;arg line="module1-outDir anotherOutDir"/>
&lt;/java>
</code></pre>
<p>
   The example above uses "<code>myBaseDir</code>" as the base directory where a separate JVM instance will run.
   Two output directories containing "<code>coverage.ser</code>" data files are specified, as command line arguments.
   Other configuration parameters can be specified through the "<code>coverage-xyz</code>" system properties.
   This separate JVM instance will read each of the "<code>coverage.ser</code>" data files, merge the coverage data in memory, and then
   generate the aggregate HTML report before exiting.
</p>

<h3 id="serial-append">
   <a href="#serial-append">4.2 Generating an aggregate report from a single data file appended after each test run</a>
</h3>
<p>
   Another way to obtain an aggregate coverage report from the execution of multiple test runs is to accumulate coverage data from all tests
   into a <em>single</em> data file.
   This can be achieved by using the same working directory for all test runs or by pointing <code>coverage-outputDir</code> to a shared
   directory, while having <code>coverage-output=<strong>serial-append</strong></code> for each test run.
   Additionally, the last test run in the sequence should also specify <code>html</code> or <code>html-nocp</code> for the
   <code>coverage-output</code> property, <em>together</em> with <code>serial-append</code>.
   Naturally, the first test run must <em>not</em> read data from this file; therefore, either the file should be deleted before the first
   test run, or ignored by having the first test run use <code>coverage-output=serial</code>.
</p>
<p>
   So, the difference between output modes "<code>serial</code>" and "<code>serial-append</code>" is that with the first we have multiple
   "<code>coverage.ser</code>" files (each in a different directory used by a separate test run), while with the second we share a single
   data file between all test runs.
</p>

<h2 id="checking">
   <a href="#checking">5 Checking minimum coverage</a>
</h2>
<p>
   If desired, JMockit Coverage can check that the final coverage percentages at the end of a test run satisfy arbitrary minimum values.
   Such checks can be specified through one or more <em>checking rules</em> assigned to the "<code>coverage-check</code>" system property
   (when more than one, they must be separated by ";" characters).
</p>
<p>
   Each checking rule must be in the form "[<em>scope</em>:]min percentage".
   There are three types of scopes:
</p>
<ul>
   <li>
      <em>Total</em>: The default when no scope is specified.
      For example, the rule "<code>80</code>" specifies that the total coverage should be at least 80%.
   </li>
   <li>
      <code>perFile</code>: Specifies minimum percentages that <em>each</em> source file must satisfy. If one or more files end up with a
      lower percentage, the check fails.
      An example: "<code>perFile:50</code>", meaning that each source file must have at least 50% of coverage.
   </li>
   <li>
      <em>Package</em>: Specifies minimum total percentage for the set of source files in a given package, including sub-packages.
      For example, the rule "<code>com.important:90</code>" specifies that total coverage for files under "<code>com.important</code>"
      should be at least 90%.
   </li>
</ul>
<p>
   All checks (if any) are performed at the end of the test run (at JVM shutdown, actually).
   Other forms of output (HTML report, serialized file) are not affected.
   When an individual check fails, a descriptive message is printed to standard output.
   If one or more checks have failed, two final actions are taken to have the fact reported: first, an empty file of name
   "<code>coverage.check.failed</code>" is created in the current working directory; second, an error (specifically, an
   <code class="type">AssertionError</code>) is thrown.
   When checks are performed but they all pass, the "<code>coverage.check.failed</code>" file, if present in the current directory, is
   deleted.
</p>
<p>
   The use of a file to mark the success or failure of coverage checks is meant to allow build tools to react accordingly, typically by
   failing the build when the file is present.
   For example, we can do the following in a Maven pom.xml file:
</p>
<pre><code>&lt;plugin>
   &lt;artifactId>maven-enforcer-plugin&lt;/artifactId>
   &lt;executions>
      &lt;execution>
         &lt;id>coverage.check&lt;/id>
         &lt;goals>&lt;goal>enforce&lt;/goal>&lt;/goals>
         &lt;phase>test&lt;/phase>
         &lt;configuration>
            &lt;rules>
               &lt;requireFilesDontExist>
                  &lt;files>&lt;file>target/coverage.check.failed&lt;/file>&lt;/files>
               &lt;/requireFilesDontExist>
            &lt;/rules>
         &lt;/configuration>
      &lt;/execution>
   &lt;/executions>
&lt;/plugin>
</code></pre>

<h2 id="maven">
   <a href="#maven">6 Activating coverage in a Maven project</a>
</h2>
<p>
   If you run tests with Maven's "test" goal, you will need the "jmockit" dependency in the <code>pom.xml</code> file (assuming the
   "<code>jmockit.version</code>" property has been properly defined):
</p>
<pre><code>&lt;dependency>
   &lt;groupId><strong>org.jmockit</strong>&lt;/groupId> &lt;artifactId><strong>jmockit</strong>&lt;/artifactId>
   &lt;version><strong>${jmockit.version}</strong>&lt;/version>
   &lt;scope>test&lt;/scope>
&lt;/dependency>
</code></pre>
<p>
   With Maven, the <code>surefire</code> plugin is the one usually responsible for running tests.
   To activate and configure the coverage tool, specify values for the appropriate "<code>coverage-xyz</code>" system properties.
</p>
<pre><code>&lt;plugin>
   &lt;artifactId>maven-surefire-plugin&lt;/artifactId>
   &lt;configuration>
      &lt;argLine>
         <strong>-javaagent:"${settings.localRepository}"/org/jmockit/jmockit/${jmockit.version}/jmockit-${jmockit.version}.jar</strong>

         &lt;!-- Coverage properties -->
         &lt;!-- At least one of the following needs to be set: -->
         -Dcoverage-output=html             &lt;!-- or: html-nocp (default if coverage is activated), serial, serial-append -->
         -Dcoverage-classes=loaded          &lt;!-- or a "*" expression for class names; if not set, measures all production code classes -->

         &lt;!-- Other properties, if needed: -->
         -Dcoverage-outputDir=my-dir        &lt;!-- default: target/coverage-report -->
         -Dcoverage-srcDirs=sources         &lt;!-- default: all "src" directories -->
         -Dcoverage-excludes=some.package.* &lt;!-- default: empty -->
         -Dcoverage-check=80                &lt;!-- default: no checks -->
      &lt;/argLine>
   &lt;/configuration>
&lt;/plugin>
</code></pre>

<h3 id="site">
   <a href="#site">6.1 Including the HTML report in a Maven site</a>
</h3>
<p>
   To have the JMockit Coverage HTML report included in the generated <a href="http://maven.apache.org/guides/mini/guide-site.html">Maven
   site</a> documentation, the <code>src/site/site.xml</code> descriptor file needs to be provided, with contents similar to what's shown
   below.
</p>
<pre><code>&lt;?xml version="1.0" encoding="UTF-8"?>
&lt;project
   xmlns="http://maven.apache.org/DECORATION/1.3.0"
   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
   xsi:schemaLocation="http://maven.apache.org/DECORATION/1.3.0
                       http://maven.apache.org/xsd/decoration-1.3.0.xsd">
   &lt;body>
      &lt;menu ref="reports"/>
      &lt;menu>
         &lt;item name="Code Coverage Report" href="../../coverage-report/index.html"/>
      &lt;/menu>
   &lt;/body>
&lt;/project>
</code></pre>

<h2 id="switching">
   <a href="#switching">7 Turning coverage off</a>
</h2>
<p>
   To temporarily turn coverage off for a particular test run, we can set the <strong><code>coverage-output</code></strong> system property
   to an unknown output format, such as "<code>-Dcoverage-output=<strong>none</strong></code>".
   The same effect will be achieved by setting "<code>-Dcoverage-classes=<strong>none</strong></code>".
</p>
<p>
   Another, more interactive, way is to manipulate the <em>read-only attribute</em> of the relevant output file, when one has already been
   generated.
   The particular file to be manipulated, always in the working directory, is "<code>coverage.ser</code>" for serialized output or
   "<code>coverage-report/index.html</code>" for HTML output.
   The file attribute is checked by JMockit at startup; when marked as read-only it cannot be overwritten, so JMockit avoids the attempt
   entirely.
   Note that the working directory can usually be selected separately for each test run configuration in the Java IDE.
   Also, a Java IDE usually provides an easy mechanism to toggle the read-only status of a file in the project:
   in IntelliJ IDEA it is done by double clicking the status bar, with the desired file opened in the editor;
   in Eclipse there is a "Read only" check box in the "Properties" screen (which can be opened by typing "Alt+Enter") for the text file
   selected in the editor.
</p>

<div id="bottom" class="navigation">
   <a href="Faking.html"><img src="go-previous.png" title="Previous chapter"></a>
   <a href="../tutorial.html"><img src="go-home.png" title="Contents"></a>
</div>
</body>
</html>